{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Satyajeet Chavan\n",
        "# Roll:381025\n",
        "# Batch-A1"
      ],
      "metadata": {
        "id": "ndlFeKQ1juor"
      },
      "id": "ndlFeKQ1juor"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AkrPt8WBjkyx"
      },
      "source": [
        "# NLP Assignment: Semantic Relationships using WordNet\n",
        "\n",
        "This notebook demonstrates how to use **WordNet** to identify:\n",
        "- Synonymy\n",
        "- Antonymy\n",
        "- Hypernymy\n"
      ],
      "id": "AkrPt8WBjkyx"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "C21BFnGxjkyy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fccadca-4eb6-4190-9e26-0cbcbccb84e9"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.corpus import wordnet as wn\n",
        "\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')"
      ],
      "id": "C21BFnGxjkyy"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smSbTDybjkyz"
      },
      "source": [
        "## Function to Find Synonyms"
      ],
      "id": "smSbTDybjkyz"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "-hFY8Qsfjkyz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9bb61b8b-558d-44a5-c450-19d322733f03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'felicitous', 'happy', 'well-chosen', 'glad'}\n"
          ]
        }
      ],
      "source": [
        "def get_synonyms(word):\n",
        "    synonyms = set()\n",
        "    for synset in wn.synsets(word):\n",
        "        for lemma in synset.lemmas():\n",
        "            synonyms.add(lemma.name())\n",
        "    return synonyms\n",
        "\n",
        "print(get_synonyms('happy'))"
      ],
      "id": "-hFY8Qsfjkyz"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIAW60MCjkyz"
      },
      "source": [
        "## Function to Find Antonyms"
      ],
      "id": "FIAW60MCjkyz"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "23m_k55Ljkyz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0dcd31bf-9a14-487c-bf8f-aae6049fad7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'unhappy'}\n"
          ]
        }
      ],
      "source": [
        "def get_antonyms(word):\n",
        "    antonyms = set()\n",
        "    for synset in wn.synsets(word):\n",
        "        for lemma in synset.lemmas():\n",
        "            if lemma.antonyms():\n",
        "                antonyms.add(lemma.antonyms()[0].name())\n",
        "    return antonyms\n",
        "\n",
        "print(get_antonyms('happy'))"
      ],
      "id": "23m_k55Ljkyz"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JEsLhbuPjkyz"
      },
      "source": [
        "## Function to Find Hypernyms"
      ],
      "id": "JEsLhbuPjkyz"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "gDUMNfc7jky0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6763b251-7e47-461f-b5a5-2c6a250853df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'lad', 'pursue', 'villain', 'cuss', 'domestic_animal', 'canine', 'scoundrel', 'support', 'follow', 'chap', 'fellow', 'domesticated_animal', 'fella', 'bloke', 'feller', 'blighter', 'unpleasant_woman', 'canid', 'sausage', 'catch', 'stop', 'disagreeable_woman', 'gent'}\n"
          ]
        }
      ],
      "source": [
        "def get_hypernyms(word):\n",
        "    hypernyms = set()\n",
        "    for synset in wn.synsets(word):\n",
        "        for hypernym in synset.hypernyms():\n",
        "            for lemma in hypernym.lemmas():\n",
        "                hypernyms.add(lemma.name())\n",
        "    return hypernyms\n",
        "\n",
        "print(get_hypernyms('dog'))"
      ],
      "id": "gDUMNfc7jky0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3XESs22jky0"
      },
      "source": [
        "## Applying WordNet on Text Data"
      ],
      "id": "N3XESs22jky0"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "P-p4JCCijky0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3b48f2f-5b7e-4969-a91f-6e3d57823ba1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Word: the\n",
            "Synonyms: set()\n",
            "Antonyms: set()\n",
            "Hypernyms: set()\n",
            "\n",
            "Word: dog\n",
            "Synonyms: {'frankfurter', 'wiener', 'hound', 'blackguard', 'Canis_familiaris', 'detent', 'cad', 'pawl', 'wienerwurst', 'firedog', 'track', 'heel', 'frump', 'dog', 'hotdog', 'trail', 'chase', 'give_chase', 'go_after', 'tag', 'dog-iron', 'chase_after', 'domestic_dog', 'weenie', 'frank', 'bounder', 'tail', 'click', 'andiron', 'hot_dog'}\n",
            "Antonyms: set()\n",
            "Hypernyms: {'lad', 'pursue', 'villain', 'cuss', 'domestic_animal', 'canine', 'scoundrel', 'support', 'follow', 'chap', 'fellow', 'domesticated_animal', 'fella', 'bloke', 'feller', 'blighter', 'unpleasant_woman', 'canid', 'sausage', 'catch', 'stop', 'disagreeable_woman', 'gent'}\n",
            "\n",
            "Word: is\n",
            "Synonyms: {'exist', 'equal', 'live', 'represent', 'embody', 'cost', 'be', 'comprise', 'constitute', 'personify', 'follow', 'make_up'}\n",
            "Antonyms: {'differ'}\n",
            "Hypernyms: {'represent', 'symbolise', 'stand_for', 'rest', 'be', 'take', 'occupy', 'symbolize', 'use_up', 'remain', 'typify', 'stay'}\n",
            "\n",
            "Word: very\n",
            "Synonyms: {'very', 'selfsame', 'identical', 'real', 'rattling', 'really'}\n",
            "Antonyms: set()\n",
            "Hypernyms: set()\n",
            "\n",
            "Word: happy\n",
            "Synonyms: {'felicitous', 'happy', 'well-chosen', 'glad'}\n",
            "Antonyms: {'unhappy'}\n",
            "Hypernyms: set()\n"
          ]
        }
      ],
      "source": [
        "text = \"The dog is very happy\"\n",
        "words = text.lower().split()\n",
        "\n",
        "for word in words:\n",
        "    print(f\"\\nWord: {word}\")\n",
        "    print(\"Synonyms:\", get_synonyms(word))\n",
        "    print(\"Antonyms:\", get_antonyms(word))\n",
        "    print(\"Hypernyms:\", get_hypernyms(word))"
      ],
      "id": "P-p4JCCijky0"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xfdNBBaHj9Id"
      },
      "id": "xfdNBBaHj9Id",
      "execution_count": 5,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}